<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Ubrigens</title>
    <link href="https://ubrigens.com/atom.xml" rel="self" />
    <link href="https://ubrigens.com" />
    <id>https://ubrigens.com/atom.xml</id>
    <author>
        <name>Jakob Rieck</name>
        <email>jakobrieck+blog@gmail.com</email>
    </author>
    <updated>2020-02-21T00:00:00Z</updated>
    <entry>
    <title>It's Simbple: Peeking Inside App Sandbox Profiles</title>
    <link href="https://ubrigens.com/posts/simbple.html" />
    <id>https://ubrigens.com/posts/simbple.html</id>
    <published>2020-02-21T00:00:00Z</published>
    <updated>2020-02-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        It's Simbple: Peeking Inside App Sandbox Profiles
        <span class="date">February 21, 2020</span>
    </h2>
    <p>I concluded <a href="https://ubrigens.com/posts/sandbox_tour.html">my previous post</a> by motivating that we should be able to audit the sandbox configurations of apps we run. Because of the way the App Sandbox works on macOS, this means we need access to a human-readable version of the sandbox profile <em>generated</em> by <code>libsandbox.dylib</code>. Unfortunately, this is not something that Apple’s software currently allows for.</p>
<p>There have been numerous projects that <em>decompile</em> sandbox bytecode back to a human-readable representation, most notably Blazakis’s <a href="https://github.com/dionthegod/XNUSandbox">XNUSandbox project</a>, Esser’s <a href="https://github.com/sektioneins/sandbox_toolkit/tree/master/sb2dot">sb2dot</a>, work by <a href="https://argp.github.io/research/">argp</a> and <a href="https://github.com/malus-security/sandblaster">SandBlaster</a>. These tools are necessary on iOS; Profiles there are only available in binary form. Most of these tools however suffer from two problems. Firstly, they are hard to keep up to date, as even small changes to the bytecode format break the tooling. Secondly, most of the tools do not produce syntactically valid SBPL and therefore cannot be recompiled. As a result, it is not possible to verify their output.</p>
<p>On macOS, things are generally simpler: Rather than reverse engineering the sandbox bytecode format, I reverse engineered how <code>libsandbox</code> internally handles entitlements, sandbox snippets and parameters to evaluate and compile sandbox profiles.</p>
<p>The result of this research is <a href="https://github.com/0xbf00/simbple"><code>simbple</code></a>, a tool that reimplements the profile evaluation process done in <code>libsandbox</code> but outputs verifiably correct, human-readable SBPL.</p>
<p>Note that <a href="https://twitter.com/sdotknight/status/1230222846120644608">@sdotknight rightfully points</a> out that there is a platform profile that <em>also</em> affects sandboxing on macOS. My approach here only considers the sandbox profile generated in userland and does not consider the platform profile, which is embedded inside of <code>Sandbox.kext</code>.</p>
<h2 id="the-anatomy-of-container.plist-files-on-macos">The Anatomy of Container.plist files on macOS</h2>
<p><code>simbple</code> takes as input an apps’ <code>Container.plist</code> file, which can be found under <code>~/Library/Containers/bundle_id/</code>. This binary-encoded plist file contains lots of useful information (<em>note</em>: launch the target app once to generate the file). Follow along using:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" title="1"><span class="co"># Built-in tools, always available</span></a>
<a class="sourceLine" id="cb1-2" title="2">$ <span class="ex">plutil</span> -convert xml1 /path/to/Container.plist -o -</a>
<a class="sourceLine" id="cb1-3" title="3"><span class="co"># Levin's excellent tools. Display the information in a simpler format.</span></a>
<a class="sourceLine" id="cb1-4" title="4">$ <span class="ex">jlutil</span> /path/to/Container.plist</a></code></pre></div>
<p>Likely taking up the most space in any <code>Container.plist</code>, the <code>SandboxProfileData</code> key holds the base64-encoded binary sandbox profile compiled by <code>libsandbox</code>.</p>
<p>Grouped under <code>SandboxProfileDataValidationInfo</code> are inputs <code>libsandbox</code> uses to compile sandbox profiles:</p>
<ol type="1">
<li><code>SandboxProfileDataValidationParametersKey</code> — Contains several “global variables” such as the user’s home directory (stored as <code>_HOME</code>), her username (<code>_USER</code>) and various (auto-generated) paths to the application bundle and temporary directories.</li>
<li><code>SandboxProfileDataValidationRedirectablePathsKey</code> — approved paths that may be accessed through symlinks</li>
<li><code>SandboxProfileDataValidationEntitlementsKey</code> — An app’s entitlements.</li>
<li><code>SandboxProfileDataValidationSnippetDictionariesKey</code> — A list of sandbox <em>snippets</em> (see previous post) included in the final profile. Each snippet is described by two keys, though only one of them — <code>AppSandboxProfileSnippetPathKey</code> — is important here. It specifies the file system path to the snippet.</li>
</ol>
<h2 id="using-simbple">Using <code>simbple</code></h2>
<p><code>simbple</code> uses existing <code>Container.plist</code> files to reuse the same parameters that were initially used by the system. This simplifies the design of the tool.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" title="1">$ <span class="ex">simbple</span> --help</a>
<a class="sourceLine" id="cb2-2" title="2"><span class="ex">Usage</span>: simbple [OPTION...] CONTAINER_METADATA</a>
<a class="sourceLine" id="cb2-3" title="3"><span class="ex">Evaluate</span> a SBPL (+ Scheme) <span class="ex">profile</span></a>
<a class="sourceLine" id="cb2-4" title="4"></a>
<a class="sourceLine" id="cb2-5" title="5">  <span class="ex">-o</span>, --output=FILE          Output file</a>
<a class="sourceLine" id="cb2-6" title="6">  <span class="ex">-p</span>, --profile=PROFILE      Base profile to evaluate. Defaults to</a>
<a class="sourceLine" id="cb2-7" title="7">                             <span class="ex">application.sb</span> profile.</a>
<a class="sourceLine" id="cb2-8" title="8">      <span class="ex">--platforms</span>=PLATFORM   sierra, high_sierra, mojave (default), <span class="ex">catalina</span></a>
<a class="sourceLine" id="cb2-9" title="9"></a>
<a class="sourceLine" id="cb2-10" title="10"> <span class="ex">Output</span> formats:</a>
<a class="sourceLine" id="cb2-11" title="11">      <span class="ex">--json</span>                 Output as JSON</a>
<a class="sourceLine" id="cb2-12" title="12">      <span class="ex">--scheme</span>               Output as SCHEME / SBPL</a>
<a class="sourceLine" id="cb2-13" title="13"></a>
<a class="sourceLine" id="cb2-14" title="14"> <span class="ex">Misc</span> options:</a>
<a class="sourceLine" id="cb2-15" title="15">      <span class="ex">--patch</span>                Patch the output profile to log all statements.</a>
<a class="sourceLine" id="cb2-16" title="16">      <span class="ex">--verify</span>               Verify semantic correctness of generated results</a>
<a class="sourceLine" id="cb2-17" title="17"></a>
<a class="sourceLine" id="cb2-18" title="18">  <span class="ex">-?</span>, --help                 Give this help list</a>
<a class="sourceLine" id="cb2-19" title="19">      <span class="ex">--usage</span>                Give a short usage message</a>
<a class="sourceLine" id="cb2-20" title="20">  <span class="ex">-V</span>, --version              Print program version</a>
<a class="sourceLine" id="cb2-21" title="21"></a>
<a class="sourceLine" id="cb2-22" title="22"><span class="ex">Mandatory</span> or optional arguments to long options are also mandatory or optional</a>
<a class="sourceLine" id="cb2-23" title="23"><span class="kw">for</span> <span class="ex">any</span> corresponding short options.</a>
<a class="sourceLine" id="cb2-24" title="24"></a>
<a class="sourceLine" id="cb2-25" title="25"><span class="ex">The</span> output is a simplified SBPL profile that can be analysed, modified and</a>
<a class="sourceLine" id="cb2-26" title="26"><span class="ex">compiled</span> as is.</a></code></pre></div>
<p>In its simplest form, simply invoke <code>simbple</code> with a path to the <code>Container.plist</code> file of the app you are interested in. Doing so will spit out the SBPL profile of the target app:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" title="1">$ <span class="ex">simbple</span> ~/Library/Containers/com.apple.calculator/Container.plist</a>
<a class="sourceLine" id="cb3-2" title="2"><span class="kw">(</span><span class="ex">version</span> 1<span class="kw">)</span></a>
<a class="sourceLine" id="cb3-3" title="3"><span class="kw">(</span><span class="ex">deny</span></a>
<a class="sourceLine" id="cb3-4" title="4">    <span class="ex">default</span></a>
<a class="sourceLine" id="cb3-5" title="5"><span class="kw">)</span></a>
<a class="sourceLine" id="cb3-6" title="6"><span class="kw">(</span><span class="ex">allow</span></a>
<a class="sourceLine" id="cb3-7" title="7">    <span class="ex">mach-register</span></a>
<a class="sourceLine" id="cb3-8" title="8">    <span class="kw">(</span><span class="ex">local-name-prefix</span> <span class="st">&quot;&quot;</span><span class="kw">)</span></a>
<a class="sourceLine" id="cb3-9" title="9"><span class="kw">)</span></a>
<a class="sourceLine" id="cb3-10" title="10"><span class="kw">(</span><span class="ex">allow</span></a>
<a class="sourceLine" id="cb3-11" title="11">    <span class="ex">mach-lookup</span></a>
<a class="sourceLine" id="cb3-12" title="12">    <span class="kw">(</span><span class="ex">xpc-service-name-prefix</span> <span class="st">&quot;&quot;</span><span class="kw">)</span></a>
<a class="sourceLine" id="cb3-13" title="13"><span class="kw">)</span></a>
<a class="sourceLine" id="cb3-14" title="14"><span class="co"># &gt; 1800 lines follow on my system</span></a></code></pre></div>
<p>The resulting sandbox profiles can be manually audited and modified, automatically patched or simply be compiled to profile bytecode using <a href="https://github.com/sektioneins/sandbox_toolkit/tree/master/compile_sb">Stefan Esser’s tool</a>. The results are useful not only to security researchers interested in studying the sandbox, but also for example to developers debugging their sandboxed applications.</p>
<p>To verify that results are <em>correct</em> — meaning compiling the output results in identical sandbox bytecode to <code>libsandbox</code>’s result — use the <code>--verify</code> option. This is yet another benefit of using existing <code>Container.plist</code> files. We can use the <code>SandboxProfileData</code> data as ground truth to check against. Sandbox compilation is still a (<a href="https://github.com/0xbf00/simbple/blob/e4211c3428a417e351b7487990d00db2a71b3b69/src/sb/verify.c#L46">mostly</a>) deterministic process.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb4-1" title="1">$ <span class="ex">simbple</span> ~/Library/Containers/com.apple.calculator/Container.plist -o /dev/null --verify</a>
<a class="sourceLine" id="cb4-2" title="2">$ <span class="bu">echo</span> <span class="va">$?</span></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="ex">0</span> <span class="co"># Verification succeeded.</span></a></code></pre></div>
<h2 id="a-teaser-the-story-of-cve-2018-4184">A Teaser: The Story of CVE-2018-4184</h2>
<p><a href="https://support.apple.com/en-us/HT208849">macOS 10.13.5 fixed CVE-2018-4184</a>, an issue with “the handling of microphone access” I reported in 2018:</p>
<pre><code>*Speech*
	Available for: macOS High Sierra 10.13.4
	Impact: A sandboxed process may be able to circumvent sandbox restrictions
	Description: A sandbox issue existed in the handling of microphone access. This issue was addressed with improved handling of microphone access.
	CVE-2018-4184: Jakob Rieck (@0xdead10cc) of the Security in Distributed Systems Group, University of Hamburg</code></pre>
<p>What was the problem? Virtually every app — no matter their entitlements — was able to use the microphone on macOS. How did I figure this out? Well, I was developing <code>simbple</code> and thought my tool couldn’t possibly work correctly: scrolling through <code>Calculator.app</code>’s results, I noticed this line in the generated profile:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode scheme"><code class="sourceCode scheme"><a class="sourceLine" id="cb6-1" title="1">(allow device-microphone)</a></code></pre></div>
<p>Refer back to my previous post to see <code>Calculator.app</code>’s entitlements, which notably do not (and did not) allow the app access to the microphone. What was going on?!</p>
</div>
]]></summary>
</entry>
<entry>
    <title>A Whirlwind Tour of the Apple Sandbox</title>
    <link href="https://ubrigens.com/posts/sandbox_tour.html" />
    <id>https://ubrigens.com/posts/sandbox_tour.html</id>
    <published>2020-02-17T00:00:00Z</published>
    <updated>2020-02-17T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        A Whirlwind Tour of the Apple Sandbox
        <span class="date">February 17, 2020</span>
    </h2>
    <p>No-one knows how to design truly secure software. Any sufficiently complex software <em>will</em> contain vulnerabilities that can be abused by motivated attackers to subvert a program’s execution. Accepting this reality, the focus of the last few decades has been on developing exploit mitigation techniques such as <em>Address Space Layout Randomisation</em> (ASLR) and <em>Data Execution Prevention</em> (DEP) which focus on <em>increasing difficulty and costs</em> for attackers.</p>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/dac_mac.svg" alt="Overview: DAC vs MAC" /><figcaption>Overview: DAC vs MAC</figcaption>
</figure>
<p>Sandboxing is one such mitigation. It aims to reduce the damage of successful attacks on the host system. On traditional UNIX systems, programs run <em>as</em> a user (in what’s referred to as <em>discretionary access control</em> — DAC), inheriting all her capabilities and permissions. Most of these capabilities and permissions however are never actually required by the executing program. Sandboxing (a form of <em>mandatory access control</em> or MAC) uses per-application security policies to limit the actions a program may take and the resources it is allowed to access; it aims to make <em>what a program can do</em> the same as <em>what a program was made to do</em>. In this way, sandboxing implements the foundational information security principle of <strong>least privilege</strong>, which states that programs and users should operate using the least amount of privilege necessary to complete a certain job. Sandboxed applications – even when compromised – can access only predefined parts of the system, limiting their damage potential and requiring attackers to escape the sandbox to compromise the system itself.</p>
<p>Security benefits afforded by sandboxing hinge on proper configuration and understanding of the sandbox mechanism itself. No mitigation is perfect; <a href="https://twitter.com/halvarflake/status/1156815950873804800">Mitigations have complexity, inspectability and debuggability costs</a>. The App Sandbox is no exception: it has had a massive impact on developers scrambling to sandbox their software which was largely designed without sandboxing in mind. Apple’s sandbox implementation lacks public documentation. It “just works”, until it doesn’t. In 2018, I wrote my Master’s Thesis on the topic. In this series of posts, I am sharing what I learned in the process. My focus today is on implementation, configuration and design internals that might not be known to a wider audience.</p>
<h3 id="threat-model">Threat Model</h3>
<p>A threat model states what you (a user / a mitigation / a security system) are protecting against (and also what’s not covered). It is crucial to motivate the need for any mitigation; Unfortunately, Apple does not provide an explicit threat model for the App Sandbox. I pieced together my own version here from available marketing materials, developer-facing documentation and public sandbox-related patents.</p>
<p>The App Sandbox “<a href="https://developer.apple.com/library/archive/documentation/Security/Conceptual/AppSandboxDesignGuide/AboutAppSandbox/AboutAppSandbox.html">is designed to contain damage to the system and the user’s data if an app becomes compromised</a>”. However, it is “<a href="https://developer.apple.com/videos/play/wwdc2011/204/">not an anti-virus system; does not target intentionally malicious software</a>”. There is no practical difference between “intentionally malicious software” and software “compromised by malicious software”. This last quote can therefore only mean that <em>sandboxing in itself cannot stop malicious applications from abusing their officially granted permissions</em>, i.e. a malicious app can steal all user data it legitimately has access to. Sandboxing however should restrict even malicious applications from accessing resources that the app is not entitled to access. This interpretation of the former quote is consistent with Apple’s own patents on the topic, which motivate the need for sandboxing by stating that a “<a href="https://patents.google.com/patent/US9280644B2/en">program may be a malicious program that is developed to intentionally cause damages</a>” and “<a href="https://patents.google.com/patent/US9280644B2/en">by restricting the execution of a program within a restricted operating environment, such damages can be greatly reduced</a>”. Related patents echo this interpretation [<a href="https://patents.google.com/patent/US8943550">1</a>, <a href="https://www.researchgate.net/publication/302691438_System_and_method_for_preserving_references_in_sandboxes">2</a>].</p>
<p>All programs are initially launched <em>non-sandboxed</em> because they “<a href="https://patents.google.com/patent/US8635663">may not have had an opportunity to compile and prepare a profile to express permitted actions</a>”. This is argued to be “<a href="https://patents.google.com/patent/US8635663">consistent with the […] design of [the Sandbox] that permits intentional user actions</a>”. Here, a user launching an application is interpreted as user intent. This little-known fact, which is completely absent from all official documentation, is the achilles heel of the whole system. Under <em>normal</em> circumstances, the sandbox is initialised before transfer is controlled to application code. However, because initialisation happens in the context of the application itself, there is precious little room for error. As it stands, there is no process to ensure applications, whose metadata suggest they should run sandboxed, actually run sandboxed. I feel that this runs counter to the idea of <em>mandatory</em> sandboxing on macOS.</p>
<h2 id="configuration">Configuration</h2>
<p>Apple’s sandbox restricts programs in what they can do on the user’s system. As every application is unique, the sandbox theoretically has to be configured individually for each app. This cumbersome process falls to developers to do. For software distributed in the Mac App Store (MAS), sandboxing is mandatory and enforced by Apple. <a href="https://svs.informatik.uni-hamburg.de/publications/2019/2019-11-Blochberger-State-of-the-Sandbox.pdf">Outside the MAS, sandboxing is still the exception, not the rule</a>.</p>
<p>To configure per-program sandbox policies, two options are available: <em>SBPL</em>, a low-level configuration language, and <em>entitlements</em>, which offer a high-level interface and are the only officially supported sandbox configuration option.</p>
<h3 id="sbpl">SBPL</h3>
<p>The Sandbox Profile Language (SBPL) is implemented on top of the Scheme programming language. In what is referred to as an embedded domain specific language (EDSL), the base language (Scheme) is extended and augmented by custom identifiers, functions and macros to encode sandbox rules.</p>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/sbpl_components.svg" alt="SBPL Language Components" /><figcaption>SBPL Language Components</figcaption>
</figure>
<p>Sandbox profiles written in SBPL consist of multiple rules specified one after the other. Later rules can overwrite preceding rules, which is commonly used to implement whitelisting profiles: Deny everything first, then selectively re-enable only what is needed. Confirmed by extensive testing, the <em>last applicable rule</em> in a profile guides the final sandbox decision for a certain resource. Each rule consists of up to four components: An <em>action</em>, one or more <em>operations</em>, and optional <em>filters</em> and <em>modifiers</em>. Actions decide whether to allow or deny resource accesses. Operations denote the kind of resource access the rule applies to. Filters restrict a rule’s effect to a subset of all resources, for example only to files in a certain directory. Lastly, modifiers change the default behaviour of the sandbox. By default, only denied resource accesses are logged; a modifier changes this. A few years back, <a href="https://twitter.com/osxreverser">@osxreverser</a> bothered to <a href="https://reverse.put.as/wp-content/uploads/2011/09/Apple-Sandbox-Guide-v0.1.pdf">document the language</a>. It’s somewhat outdated, but still very useful.</p>
<p>While the core SBPL language as described above is conceptually simple, SBPL profiles can include arbitrary Scheme code to dynamically <em>generate sandbox rules during evaluation</em>. Consider the following two SBPL snippets; Their compiled sandbox bytecode is identical.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode scheme"><code class="sourceCode scheme"><a class="sourceLine" id="cb1-1" title="1">(version <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-2" title="2">(allow file-read-data</a>
<a class="sourceLine" id="cb1-3" title="3">	(subpath <span class="st">&quot;/usr/bin&quot;</span>)</a>
<a class="sourceLine" id="cb1-4" title="4">	(subpath <span class="st">&quot;/usr/local&quot;</span>)</a>
<a class="sourceLine" id="cb1-5" title="5">	(with report))</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode scheme"><code class="sourceCode scheme"><a class="sourceLine" id="cb2-1" title="1">(version <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-2" title="2">(<span class="ex">define</span><span class="fu"> </span>(usr_plus suffix) (<span class="kw">string-append</span> <span class="st">&quot;/usr/&quot;</span> suffix))</a>
<a class="sourceLine" id="cb2-3" title="3">(<span class="ex">define</span><span class="fu"> </span>(file-read-rule action filter)</a>
<a class="sourceLine" id="cb2-4" title="4">	(action file-read-data</a>
<a class="sourceLine" id="cb2-5" title="5">			filter</a>
<a class="sourceLine" id="cb2-6" title="6">			(with report)))</a>
<a class="sourceLine" id="cb2-7" title="7"></a>
<a class="sourceLine" id="cb2-8" title="8">(file-read-rule allow</a>
<a class="sourceLine" id="cb2-9" title="9">	(require-any </a>
<a class="sourceLine" id="cb2-10" title="10">		(subpath (usr_plus <span class="st">&quot;bin&quot;</span>))</a>
<a class="sourceLine" id="cb2-11" title="11">		(subpath (usr_plus <span class="st">&quot;local&quot;</span>))))</a></code></pre></div>
<p>Developers wishing to write SBPL sandbox profiles directly call <code>sandbox_init</code> from their application to voluntarily enable sandboxing. Well intentioned power users can use the <code>sandbox-exec</code> command line utility to run third-party software in custom sandboxes. Don’t bother doing this however; the software will not work correctly. On the off chance it does work correctly, your sandbox profile will be too permissive.</p>
<p>SBPL is complex and difficult to use, even for experienced developers. Though only rarely used <em>directly</em> nowadays, it still forms the foundation for sandboxing on macOS and therefore remains important to understand.</p>
<h3 id="entitlements">Entitlements</h3>
<p><em>Entitlements</em> were introduced for reasons of usability. A “<a href="https://patents.google.com/patent/US20130283344">developer does not need to know how to program or set up a set of rules for the purpose of generating a security profile</a>”. Instead, developers specify entitlements that represent the resources and capabilities their software needs to use (and hopefully no others).</p>
<p>Entitlements are not specific to sandboxing; They are also used for <em>iCloud</em>, <em>Push Notifications</em> and <em>Apple Pay</em>, to name just a few. At its core, each <em>entitlement</em> is a key-value pair, where the key is a string identifying the entitlement and the value configures the entitlement. Values can be of any type supported in property lists, including booleans, strings, dictionaries or arrays. <em>Entitlements</em> are then simply a collection of a program’s individual capabilities. Developers add the entitlements their applications require using Xcode or manually by editing a property list file. This list is securely embedded in the target program as part of its code signature and cannot be tampered with without invaliding an app’s cryptographic code signature. Using the <code>codesign</code> utility shows you which entitlements are embedded in binaries on your system:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode sh"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" title="1">$ <span class="ex">codesign</span> -d —entitlements :- /Applications/Calculator.app</a>
<a class="sourceLine" id="cb3-2" title="2"><span class="va">Executable=</span>/Applications/Calculator.app/Contents/MacOS/Calculator</a>
<a class="sourceLine" id="cb3-3" title="3"><span class="op">&lt;</span><span class="ex">?xml</span> version=“1.0” encoding=“UTF-8”?<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-4" title="4"><span class="op">&lt;</span>!<span class="ex">DOCTYPE</span> plist PUBLIC “-//Apple//DTD PLIST 1.0//EN” “http://www.apple.com/DTDs/PropertyList-1.0.dtd”<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-5" title="5"><span class="op">&lt;</span><span class="ex">plist</span> version=“1.0”<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-6" title="6"><span class="op">&lt;</span><span class="ex">dict</span><span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-7" title="7">	<span class="op">&lt;</span><span class="ex">key</span><span class="op">&gt;</span>com.apple.security.app-sandbox<span class="op">&lt;</span>/key<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-8" title="8">	<span class="op">&lt;</span><span class="ex">true</span>/<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-9" title="9">	<span class="op">&lt;</span><span class="ex">key</span><span class="op">&gt;</span>com.apple.security.files.user-selected.read-write<span class="op">&lt;</span>/key<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-10" title="10">	<span class="op">&lt;</span><span class="ex">true</span>/<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-11" title="11">	<span class="op">&lt;</span><span class="ex">key</span><span class="op">&gt;</span>com.apple.security.network.client<span class="op">&lt;</span>/key<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-12" title="12">	<span class="op">&lt;</span><span class="ex">true</span>/<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-13" title="13">	<span class="op">&lt;</span><span class="ex">key</span><span class="op">&gt;</span>com.apple.security.print<span class="op">&lt;</span>/key<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-14" title="14">	<span class="op">&lt;</span><span class="ex">true</span>/<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-15" title="15"><span class="op">&lt;</span>/<span class="ex">dict</span><span class="op">&gt;</span></a>
<a class="sourceLine" id="cb3-16" title="16"><span class="op">&lt;</span>/<span class="ex">plist</span><span class="op">&gt;</span></a></code></pre></div>
<p>Here we see <code>Calculator.app</code>’s entitlements. Applications enabling the App Sandbox using the <code>com.apple.security.app-sandbox</code> entitlement are automatically sandboxed before any application code has the chance to execute (or so in theory…). Apple mandates sandboxing for applications from the MAS and ensures new apps possess this crucial entitlement. <code>Calculator.app</code> further declares entitlements allowing it to make outbound network connections (<code>*.network.client</code>), print, as well as read <em>and</em> write user-selected files. However, <code>Calculator.app</code> will for example never be able to use the microphone.</p>
<p>The list of documented (and undocumented) entitlements grows with every new macOS release. Check out <a href="http://newosxbook.com/ent.jl">Levin’s entitlement database</a> and setup <a href="https://github.com/ChiChou/wiggle">wiggle</a> on your Mac to investigate further.</p>
<p>In contrast to SBPL, entitlements are easy to understand and use. They hide the underlying complexity of the sandbox from developers, at the expense of policy flexibility.</p>
<h2 id="architecture">Architecture</h2>
<p>Apple’s sandbox is made up of components both in user space and in the kernel. Kernel components “<a href="https://patents.google.com/patent/US20130283344">increase security and provide an efficient mechanism</a>”. The following graphic and text gives an overview of some of these components and their interactions.</p>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/architecture.svg" alt="Overview: Sandboxing Architecture on macOS" /><figcaption>Overview: Sandboxing Architecture on macOS</figcaption>
</figure>
<p>It is important to understand that <strong>neither profiles written in SBPL nor the entitlements a program has are the <em>actual</em> sandbox security policy enforced at runtime</strong>. Instead, <code>libsandbox</code> (1) is responsible for <em>compiling</em> a sandbox profile for the application, which is then passed through the kernel (3) to the <code>Sandbox.kext</code> kernel extension (4) for enforcement. During runtime, this kernel extension interacts with <code>sandboxd</code> (2) for logging.</p>
<p>macOS’s XNU kernel contains a port of TrustedBSD’s <em>mandatory access control</em> (MAC) framework, which notifies so-called <em>policy modules</em> whenever monitored functionality is accessed by processes. <code>Sandbox.kext</code> is one such policy module. It registers itself with the MAC framework on startup and is subsequently consulted whenever one of hundreds of monitored system calls is executed by a sandboxed program. Prior to executing the actual system call, hooks from the MAC framework call out to all registered policy modules. Each policy module can inspect the arguments and the current system state to decide whether the operation should proceed or not. If a single policy module denies an operation, the corresponding operating is cancelled and an error message is returned to the calling process (<a href="https://dl.packetstormsecurity.net/papers/general/apple-sandbox.pdf">h/t</a> <a href="https://twitter.com/justdionysus">@dion</a>).</p>
<p><code>Sandbox.kext</code> queries the compiled sandbox profile to check whether requested operations are allowed. The sandbox additionally supports so called <em>dynamic extensions</em>. As the name implies, these are capabilities dynamically added and removed from an application’s sandbox during its runtime. For instance, if a user drags-and-drops a file into an application, the application’s sandbox is automatically extended to allow access to this file. I did not look at dynamic extensions in more detail in my thesis.</p>
<h3 id="sandboxing-lifecycle">Sandboxing Lifecycle</h3>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/lifecycle.svg" alt="Overview: Sandboxing Lifecycle" /><figcaption>Overview: Sandboxing Lifecycle</figcaption>
</figure>
<p>As was already touched upon in the Threat Model, applications on macOS <em>always</em> start out non-sandboxed. During their lifetime, they can <em>become</em> sandboxed. Once sandboxed, an application cannot remove the restrictions again. There are two different ways for applications to end up sandboxed:</p>
<ol type="1">
<li>Given a textual SBPL sandboxing policy, programs can explicitly call <code>sandbox_init</code> or one of its variants to impose a sandbox on itself. This can be done at any point during the lifetime of a program and is completely voluntary. Though more powerful than using entitlements, it is significantly harder to configure, in addition to being deprecated and completely unsupported. Only <a href="https://www.google.com/search?q=site:opensource.apple.com+%22sandbox_init%22">Apple-internal daemons</a>, as well as complex third-party software such as <a href="https://hg.mozilla.org/mozilla-central/file/tip/security/sandbox/mac/SandboxPolicyContent.h">Mozilla’s Firefox</a> and <a href="https://www.chromium.org/developers/design-documents/sandbox/osx-sandboxing-design">Chromium</a> make use of this technique.</li>
<li>If the code signature of the program contains entitlements configuring the sandbox, <code>dyld</code>, the dynamic linker, initialises the sandbox before control is passed to the program’s entry point. Sandbox initialisation in this way is involuntary in the sense that apps have no say in the matter. For an in-depth walkthrough of how this works, check out <a href="https://geosn0w.github.io/A-Long-Evening-With-macOS's-Sandbox/">this article</a> and refer to <a href="https://github.com/0xbf00/libsecinit">my own reverse-engineered</a> <code>libsystem_secinit.dylib</code>, which reimplements part of puzzle. The App Sandbox is mandated for apps from the Mac App Store. Usually, if third party apps outside the store are sandboxed, they also use this technique.</li>
</ol>
<h2 id="a-closer-look-at-libsandbox">A Closer Look at <code>libsandbox</code></h2>
<p>No matter whether the app makes use of the App Sandbox or uses the legacy sandboxing interface, at one point <code>libsandbox</code> will be invoked to compile the security profile for the application. Conceptually, this library does two different things, though they overlap in the actual implementation. Firstly, the library contains a custom Scheme interpreter based on <code>TinySCHEME</code>, modified to handle the full SBPL language. Secondly, it contains functionality to produce (<em>“compile”</em>) the sandbox bytecode for use by the sandbox’s kernel component.</p>
<p>For applications using the legacy <code>sandbox_init</code> sandboxing interface directly, <code>libsandbox</code> is provided with a textual sandboxing profile written in a mixture of SBPL and Scheme. The library’s embedded interpreter <em>evaluates</em> (i.e. <em>executes</em>) this profile because, as described previously, SBPL profiles can contain arbitrary Scheme code that <em>generates sandbox rules during evaluation</em>. Recall the two <em>different</em> SBPL snippets shown previously that <em>resulted in identical bytecode</em>. The final ruleset generated during evaluation is then serialised and output in the opaque binary format.</p>
<p>The ability to dynamically generate sandbox rules using Scheme code forms the foundation of the <em>App Sandbox</em>, which is used by the vast majority of applications. Here, <code>libsandbox</code> is invoked by the private <code>AppSandbox</code> framework, which first collects a number of inputs for <code>libsandbox</code>:</p>
<ol type="1">
<li><em>Entitlements</em>: These are extracted from the code signature of the application</li>
<li><em>Additional Parameters</em>: Values such as an app’s bundle identifier and the path to the user’s home directory. These might be referenced by <em>sandbox snippets</em> (see below) during evaluation.</li>
<li><em>Sandbox Snippets</em>: A list of SBPL profiles to evaluate, the most important one being the abstract <code>application.sb</code> application sandboxing base profile. In addition, some of Apple’s frameworks require custom sandbox rules to function properly. These rules are specified in a <code>.sb</code> file as part of the framework bundle. When an application links against such a framework, the corresponding sandbox snippet is included in the list, too.</li>
</ol>
<figure>
<img src="https://ubrigens.com/assets/images/sandbox_tour/libsandbox_flow.svg" alt="Overview: Inner Workings of libsandbox" /><figcaption>Overview: Inner Workings of <code>libsandbox</code></figcaption>
</figure>
<p>Profile compilation for the App Sandbox is slightly more complicated compared to the legacy sandboxing mechanism. Starting out, <code>libsandbox</code> makes entitlements and additional parameters available to SBPL profiles (scripts) it evaluates. It then starts by evaluating <code>application.sb</code> (referred to as <em>“abstract base profile”</em> in the graphic). This profile, which you can find on your system under <code>/System/Library/Sandbox/Profiles/application.sb</code>, dynamically generates sandbox rules while taking into account supplied entitlements and parameters. As shown in the graphic for example, the <code>(allow device-microphone)</code> sandbox rule is only emitted if the application possesses one of the sanctioned entitlements. Similarly, the profile references the user’s home directory (supplied as part of the /additional parameters/) using the <code>param</code> function to emit correct paths for the user’s machine. Lastly, each additional SBPL snippet is evaluated, building the final list of sandbox rules (referred to in the graphic as <em>“concrete app profile”</em>). Note that while the graphic shows the <em>concrete app profile</em> as consisting of human-readable SBPL rules, this is a simplification. In reality the rules are encoded in complex data structures within <code>libsandbox</code>, which are finally <em>compiled</em> into the opaque binary format for <code>Sandbox.kext</code> to use.</p>
<p>I motivated this post by saying that sandboxing’s effectiveness depends on proper configuration. To decide whether <em>anything</em> is proper or not, you need to be able to look at (<em>audit</em>) it. Can you be sure what rules complex Scheme code will generate? Do you know what each entitlement <em>actually does</em> to your sandbox? To answer these questions, you would need access to a human-readable version of the <em>actual sandbox profile</em>. Unfortunately, there is no such thing on macOS. You have to trust the system “just works”.</p>
</div>
]]></summary>
</entry>
<entry>
    <title>Should You Use Film Infrared Cleaning? (Digital ICE)</title>
    <link href="https://ubrigens.com/posts/digital_ice.html" />
    <id>https://ubrigens.com/posts/digital_ice.html</id>
    <published>2017-07-18T00:00:00Z</published>
    <updated>2017-07-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        Should You Use Film Infrared Cleaning? (Digital ICE)
        <span class="date">July 18, 2017</span>
    </h2>
    <p>Short answer: <strong>Yes</strong>. For a practical example, play around with the slider at the bottom.</p>
<hr />
<p>Digital ICE has been around for a long time. According to Wikipedia <a href="https://en.wikipedia.org/wiki/Digital_ICE">[1]</a>, the technique is originally from the 1960s, but nowadays is often found in film negative scanners. Different manufacturers have used the same underlying tech for the past ten years. Apart from <em>Digital ICE</em>, you might therefore have a scanner which features <em>Magic Touch</em> or Canon’s <em>FARE</em>. While the exact implementations are almost guaranteed to differ, they all use an additional infrared lamp to scan negative film with. Dust and scratches can be detected reliably for standard color film using this method, but due to the different structure of black and white film, the technique does not work here.</p>
<p>After the scan, when dust and scratches have been detected by the scanner, it is now up to the scanning software to replace these <em>faulty</em> places with content that essentially looks more pleasing to the human eye. Because these changes are done only where defects have been detected, the method does not affect the overall image quality negatively. Filling “holes” in images with computer generated content is called <em>inpainting</em> and also has been around for quite some time <a href="https://www.youtube.com/watch?v=1DoCQMelAMM">[2,</a> <a href="https://www.microsoft.com/en-us/research/product/computational-photography-applications/image-composite-editor/">3]</a>. More advanced versions of this technique have made it into Adobe’s Photoshop (“Content Aware Fill”), but your scanning program likely implements their own technique. Unfortunately, I’ve yet to find a way to use Photoshop’s “Content Aware Fill” to fixup my negatives. Still, <strong>you should definitely be using Digital ICE</strong> (or related technology).</p>
<p>Below you’ll find a before-after comparison of a recent photo I scanned. The negative itself is well over 20 years old. On the left hand side you see what happens if you scan with <em>Infrared cleaning</em> turned off, on the right hand side with <em>Infrared cleaning</em> set to <em>Light</em> (I’m using VueScan for these experiments!).</p>
<p>Manually retouching the photo would take <em>hours</em>.</p>
<p>Note: Using Digital ICE or similar techniques does not mean you should not clean your negatives properly before scanning. The cleaner your negatives are, the less content has to be replaced by algorithms.</p>
<!--html_preserve-->
<div class="slide-comparison">
<img src="https://ubrigens.com/assets/images/cat_clean.jpg">
<div class="resized">
<img src="https://ubrigens.com/assets/images/cat_littered.jpg">
</div>
<div class="divider">

</div>
</div>
<!--/html_preserve-->
<script src="https://ubrigens.com/assets/js/image-comparison-slider.min.js"></script>
</div>
]]></summary>
</entry>
<entry>
    <title>Papers - January 2016</title>
    <link href="https://ubrigens.com/posts/papers_january16.html" />
    <id>https://ubrigens.com/posts/papers_january16.html</id>
    <published>2016-01-11T00:00:00Z</published>
    <updated>2016-01-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        Papers - January 2016
        <span class="date">January 11, 2016</span>
    </h2>
    <p>Second installment of the <em>Papers</em> series. Be sure to read <a href="https://ubrigens.com/posts/papers_september.html">the first one</a> from a couple of months ago!</p>
<p><a href="http://arxiv.org/pdf/1511.07528v1.pdf">&gt; <strong>The Limitations of Deep Learning in Adversarial Settings</strong> (2015)</a></p>
<blockquote>
<p><em>Adversarial samples</em> are samples produced in such way that they differ minimally from beneign samples. Even though humans still correctly classify them, a DNN fails and produces class labels controlled by the adversary. Well written, <em>understandable</em> paper. Impressive.</p>
</blockquote>
<p><a href="http://www.ieee-security.org/TC/SPW2014/papers/5103a140.PDF">&gt; <strong>Mind your language(s): A discussion about languages and security</strong> (2014)</a></p>
<blockquote>
<p>LangSec is a hugely important part of InfoSec that does not currently receive the attention it deserves. Absence of type-checking, (implicit) casts and overloading all constitute possible security problems that need to be carefully addressed. The paper is full of interesting tidbits, quotes and rather amusing vulnerabilities (Try to <em>rm</em> a file called <em>-rf</em> for instance).</p>
</blockquote>
<p><a href="https://www.cs.columbia.edu/~smb/papers/GoingBright.pdf">&gt; <strong>Going Bright: Wiretapping without Weakening Communications Infrastructure</strong> (2013)</a></p>
<blockquote>
<p>“Taking advantage of [existing vulnerabilities] is far preferable to introducing new vulnerabilities into other applications or infrastructure […]”. Better, yes, but not <em>good</em>. <a href="http://www.reuters.com/article/us-cybersecurity-nsa-flaws-insight-idUSKCN0SV2XQ20151107">Also somewhat related.</a></p>
</blockquote>
<p><a href="https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-kemerlis.pdf">&gt; <strong>ret2dir: Rethinking Kernel Isolation</strong> (2014)</a></p>
<blockquote>
<p>Interesting, practical paper doing useful research. The authors, which were also nominated for a <a href="http://pwnies.com/nominations/">Pwnie</a>, also released all source code.</p>
</blockquote>
<p><a href="http://www.mysmu.edu/phdis2008/yqcheng.2008/ROPecker-NDSS14.pdf">&gt; <strong>ROPecker: A Generic and Practical Approach for Defending Against ROP Attacks</strong> (2014)</a></p>
<blockquote>
<p>Cool research on ROP attack mitigations. Does not modify the binary - neither on disk or at runtime - and is thus much more suited to general application. Unfortunately only protects user-space code and there are a few ways to bypass the techniques. Fortunately, these techniques greatly increase the cost of an adversary, reducing the likelyhood you will fall victim to an attack.</p>
</blockquote>
<p><a href="https://ubrigens.com#TODO#">&gt; <strong>Protecting Android Apps Against Reverse Engineering by the Use of the Native Code</strong> (2015)</a></p>
<blockquote>
<p>The authors propose techniques to raise efforts needed to reverse engineer Android applications by introducing <em>one</em> native function responsible for field accesses, method call indirection and opaque predicates. Not a huge fan, considering the performance (and therefore <em>battery</em>) impact is on the order of 10x to 30x.</p>
</blockquote>
<p>Also worth reading:</p>
<ul>
<li><a href="https://www.iseclab.org/papers/cutwail-LEET11.pdf"><strong>The Underground Economy of Spam: A Botmaster’s Perspective of Coordinating Large-Scale Spam Campaigns</strong> (2011)</a></li>
<li><a href="https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf"><strong>A Computational Approach for Obstruction-Free Photography</strong> (2015)</a></li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Papers - September 2015</title>
    <link href="https://ubrigens.com/posts/papers_september.html" />
    <id>https://ubrigens.com/posts/papers_september.html</id>
    <published>2015-09-10T00:00:00Z</published>
    <updated>2015-09-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        Papers - September 2015
        <span class="date">September 10, 2015</span>
    </h2>
    <p>I am starting a new series on this site, where I comment on papers I read in the last few weeks. I intend to publish these articles bimonthly!</p>
<p><a href="https://www.iseclab.org/papers/beagle.pdf">&gt; <strong>Lines of Malicious Code: Insights Into the Malicious Software Industry</strong> (2012)</a></p>
<blockquote>
<p>Some interesting techniques but almost no usable results: Malware changes over time, but remains stable for large periods of time. Who would have thought that binary matching and diffing were hard and you trade off speed versus accuracy? The bottom line is: malware changes just as normal software does, adding approximately 100-300 LoC on average in each new version.</p>
</blockquote>
<p><a href="https://users.ece.cmu.edu/~tdumitra/public_documents/bilge12_zero_day.pdf">&gt; <strong>Before We Knew It - An Empirical Study of Zero-Day Attacks In The Real World</strong> (2012)</a></p>
<blockquote>
<p>The paper uses surprisingly simple tactics to achieve its result, which is the identification of 18 zero-day attacks - of which 11 were unknown at the time of publication - from more or less publicly available data (Symantec’s WINE dataset).</p>
</blockquote>
<blockquote>
<p>Some of the more interesting tidbits are these:</p>
</blockquote>
<blockquote>
<ul>
<li>A ‘typical zero-day attack’ lasts 312 days on average</li>
<li>10% of security patches have bugs of their own (Check out <a href="https://xuanwulab.github.io/2015/08/27/Poking-a-Hole-in-the-Patch/">[1,</a> <a href="http://blog.exodusintel.com/2015/08/13/stagefright-mission-accomplished/">2]</a> for recent examples)</li>
<li>The number of attacks increase 2 - 100 000 times after the public disclosure of vulnerabilites</li>
</ul>
</blockquote>
<p><a href="https://www.cs.indiana.edu/~minaxi/pubs/acsac12-vv.pdf">&gt; <strong>Twitter Games: How Successful Spammers Pick Targets</strong> (2012)</a></p>
<blockquote>
<p>Spammers use Twitter with varying degree of success. Spam tacts evolve quickly and are hard to analyse automatically. Ratelimiting and, more generally, costs associated with the modern Twitter API result in studies that work on very small data sets and are thus not really representative. Since the article is a couple of years old, chances are the findings are irrelevant by now. Be sure to check out related works if you are interested in the topic.</p>
</blockquote>
<p><a href="https://www.iseclab.org/papers/vanity_cracks_malware_ccs2012.pdf">&gt; <strong>Vanity, Cracks and Malware - Insights into the Anti-Copy Protection Ecosystem</strong> (2012)</a></p>
<blockquote>
<p>Surprise! Cracks are used by criminals to spread malware! The original source - dubbed the <em>scene</em> - is mostly fine and has mechanisms to deal with malicious or faulty uploads (which result in what’s called a <em>NUKE</em>). Instead, the intermediate distribution steps such as OCH, BitTorrent or even Usenet, allow parties unrelated to the original warez groups to attach their own malicious software.</p>
</blockquote>
<blockquote>
<ul>
<li>The authors could be the only people to ever purchase a <a href="http://letitbit.net">Letitbit</a> premium account</li>
<li><em>AVG free</em> apparently was at some point a <em>state of the art</em> AV</li>
<li>Authors speculate that they could have found <em>0-day malware</em>, because they found new samples.</li>
<li>Even though their AV reported 2/3 of all files to be infected, only 13.33% actually infected the host. This is what’s called a <em>false positive</em>, and is most likely not because the malicious code did not manage to persist, as the authors seem to assume.</li>
</ul>
</blockquote>
<blockquote>
<p>The article highlights the need for users to be able to verify the integrity of a certain crack or keygen downloaded through untrusted channels. To this end, it might be useful for release groups to sign their releases. The exact infrastructure to support this endeavor could be as simple as using PGP.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2015/767.pdf">&gt; <strong>Dual EC: A Standardized Back Door</strong> (2015)</a></p>
<blockquote>
<p>Offers interesting views behind the scenes of the Dual EC standardization effort. Be sure to also check out Schneier’s paper <a href="https://eprint.iacr.org/2015/097.pdf">“Surreptitiously Weakening Cryptographic Systems”</a>, as well as <a href="https://projectbullrun.org/dual-ec/">Project Bullrun</a>, the project’s website containing lots of referenced documents.</p>
</blockquote>
<p><a href="http://arxiv.org/pdf/1509.00459v1.pdf">&gt; <strong>Visualizing signatures of human activity in cities across the globe</strong> (2015)</a></p>
<blockquote>
<p>What the hell is that font? Short and sweet paper, though it’s <a href="http://www.manycities.org/">interactive web counterpart</a> is much more exciting.</p>
</blockquote>
</div>
]]></summary>
</entry>
<entry>
    <title>Demystifying iOS App Cracking</title>
    <link href="https://ubrigens.com/posts/demystifying_app_cracking.html" />
    <id>https://ubrigens.com/posts/demystifying_app_cracking.html</id>
    <published>2015-06-16T00:00:00Z</published>
    <updated>2015-06-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        Demystifying iOS App Cracking
        <span class="date">June 16, 2015</span>
    </h2>
    <p>This article is not a guide on how to crack iOS applications. It merely tries to explain the techniques used to circumvent the iOS DRM system. I do not in any way condone piracy.</p>
<hr />
<p>iOS apps come in packages with the filename extension <em>.ipa</em>. These packages are just renamed zip archives, and can easily be unpacked using appropriate tools. The resulting directory tree is of little interest to us here and has been documented elsewhere <a href="https://en.wikipedia.org/wiki/.ipa_(file_extension)">[1,</a> <a href="https://www.theiphonewiki.com/wiki/IPA_File_Format">2]</a>.</p>
<p>For a cracker the most interesting file is the executable, which can be found by inspecting the <code>Info.plist</code> file, specifically be looking up the value for the <code>CFBundleExecutable</code> key. Today, most binaries contain code for multiple architectures. Such files are called <em>fat</em> binaries, stemming from the fact that they contain code for multiple architectures like <em>ARMv7</em>, <em>ARMv7s</em> and <em>ARM64</em> (also known as <em>ARMv8</em>). On the Mac, the same concept is used, but the code inside such binaries typically targets Intel’s 32- and 64-bit processors.</p>
<p>At runtime, the dynamic linker (almost always <em>dyld</em>) will examine the file, determine the best architecture to run, process all load commands and then proceeds to execute the chosen slice. More information on the file format - <em>MachO</em> - and information on the various load commands can be found on Apple’s website <a href="https://developer.apple.com/library/mac/documentation/DeveloperTools/Conceptual/MachORuntime/index.html">[3]</a>.</p>
<figure>
<img src="https://ubrigens.com/assets/images/blackbox_decryption.svg" alt="Architecture selection at runtime" /><figcaption>Architecture selection at runtime</figcaption>
</figure>
<p>Essentially, the OS kernel can be treated as a black box that automatically decrypts part of the supplied binary - The part that runs <em>best</em> on the available hardware. In this case, <code>posix_spawn</code> was chosen to launch the process, but any other similar function will do. To simplify things, the figure ignores the fact that only the decrypted portion is present in memory after launch.</p>
<p>On iOS, all third-party code must be code-signed by a valid developer ID. The code signature is specified as a load command just after the MachO header, so each <em>slice</em> - rather than the whole fat binary - has its own code signature. The signature is validated by the kernel, and apps with an invalid signature are killed immediately. On non-jailbroken devices, the integrity of the application bundle is ensured by the OS. On jailbroken devices, most of an apps’ contents are allowed to change, since critical security features are gone. Still, a code signature must be present for code to run - however, in this case, a pseudo signatures like those produced by <em>jtool</em> and <em>ldid</em> suffice.</p>
<p>Popular cracking tools such as <em>Clutch</em> <a href="https://github.com/KJCracks/Clutch">[4]</a> use an ugly workaround to crack as many slices of an iOS binary as possible: Let’s say an app contains code for all three architectures mentioned above. <em>Clutch</em> is then going to patch the header of the executable three times, each time forcing the operating system to execute a different slice. Obviously this only works if the device can execute the slice, meaning that an iPhone 6 can be used to create cracks containing decrypted copies of all three architectures, whereas an iPhone 4S can only decrypt the <em>ARMv7</em> portion.</p>
<p>Here is the process visualized. Again, the device in question is an iPhone 5.</p>
<figure>
<img src="https://ubrigens.com/assets/images/clutch.svg" alt="Clutch on iPhone 5" /><figcaption>Clutch on iPhone 5</figcaption>
</figure>
<p>In this case, the original binary contains three slices for different architectures. Because we are on iPhone 5 which uses a <em>ARMv7s</em> compatible CPU, normally only the corresponding slice would be executed. <em>Clutch</em> abuses the fact that ARM processors are generally backwards compatible, meaning devices capable of running <em>ARMv7s</em> code can also execute <em>ARMv7</em> code. In total, <em>Clutch</em> executes the app twice, once for each supported architecture. In order to force the operating system to execute a specific slice, all other slices are set to contain Intel code.</p>
<p>Each slice is dumped by first spawning the new process using <code>posix_spawn</code> in a suspended state. This is accomplished by using the Apple only flag <code>POSIX_SPAWN_START_SUSPENDED</code>. No code by the application is ever executed, but the slice in question is automatically decrypted by the OS. Next, after aquiring the mach port for the spawned process using <code>task_for_pid</code>, its memory is copied to disk. Lastly, headers are patched where necessary (for example the <code>LC_ENCRYPTION_COMMAND</code> needs to be updated to reflect the fact that the new binary is no longer encrypted) and the processing of the next slice begins. If you are interested in the implementation details, check out the source code <a href="https://github.com/KJCracks/Clutch">[4]</a>.</p>
<p>Finally, the decrypted pieces are combined into a new binary. Because the iPhone 5 does not support <em>ARM64</em>, the output only contains two slices. Still, the binary runs on iPhone 6 - albeit possibly a tiny bit slower.</p>
<p>It is important for developers to understand how this process works. Although the public opinion is largely shaped by discussions about piracy, there are also legitimate uses for app cracking: Penetration testers looking for vulnerabilities in a clients’ app or developers working on <em>reproducible builds</em> <a href="https://github.com/WhisperSystems/Signal-iOS/issues/641">[5]</a>. There are profound implications for what I’ve written in here when we take into consideration <em>App Thinning</em> and <em>Bitcode</em>.<del>, which will be the topic of my next article! Stay tuned!</del></p>
<p>I am not going to get around to write an entire article on this topic, so here is the gist of it:</p>
<p><em>App Thinning</em> results in binaries that only contain one architecture, forcing crackers to use multiple devices to crack each individual slice and then manually combine them to create a version that runs on as many devices as possible. <em>Bitcode</em> on the other hand could allow Apple to create personalized versions of apps, allowing them to trace accounts that distribute cracked versions of an app (fittingly referred to as <em>traitor tracing</em>). If used, both technologies will hopefully reduce the impact of application cracking on the revenue of iOS developers.</p>
<hr />
<p>Changelog:</p>
<ul>
<li>June 17, 2015: Fixed date, changed title to better reflect the contents of this article.</li>
<li>September 10, 2015: Added disclaimer, added section on impact of <em>App Thinning</em> and <em>Bitcode</em> in iOS 9</li>
<li>November 1, 2018: Updated parts of the article.</li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Origins</title>
    <link href="https://ubrigens.com/posts/origins.html" />
    <id>https://ubrigens.com/posts/origins.html</id>
    <published>2015-04-28T00:00:00Z</published>
    <updated>2015-04-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="post">
    <h2>
        Origins
        <span class="date">April 28, 2015</span>
    </h2>
    <p>This is my personal site, where I mostly write about fun little projects related to information security.</p>
<p>Content sprinkled in between could also be related to Haskell, C, or the myriad of tools useful for reverse engineering.</p>
<p>The design of this site is pretty much stolen from <a href="http://raysohn.com">Raymond Sohn</a>. Once upon a time, his site featured more content than the three dots you find there now. Ray, I don’t know what happened to you, but I hope you are OK! Thank you for lending me your design. I am sure it would have taken at least another year before something appeared on here otherwise.</p>
</div>
]]></summary>
</entry>

</feed>
